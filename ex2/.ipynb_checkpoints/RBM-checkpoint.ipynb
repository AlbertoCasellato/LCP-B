{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f90d4038",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- change the name of the *test* method\n",
    "- check what *pz* is\n",
    "- provare diverso dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad95cb",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from sklearn.datasets import fetch_openml\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5aeb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LOGlike(object):\n",
    "    \"\"\"\n",
    "    FORMAT:\n",
    "    D = 784      # visible\n",
    "    L = 12       # hidden\n",
    "    M = len(x)   # number of data points\n",
    "    a = np.random.uniform(-1, 1, D)\n",
    "    b = np.random.uniform(-1, 1, L)\n",
    "    x = np.random.randint(0, 2, (M, D))\n",
    "    z = np.random.randint(0, 2, L)\n",
    "    w = np.random.uniform(-1, 1, (D, L))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x, L, spins = False):\n",
    "        self.a = None # a   # visible\n",
    "        self.b = None # b   # hidden\n",
    "        self.D = None # a.shape[0]\n",
    "        self.L = None # b.shape[0]\n",
    "        self.x = x\n",
    "        self.spins = spins\n",
    "        self.M = len(x)\n",
    "        self.w = None # w\n",
    "        self.q = None\n",
    "        self.k = None\n",
    "        self.esit = []\n",
    "        self.esit_ix = []\n",
    "        self.z = None\n",
    "        #\n",
    "    #####\n",
    "    #\n",
    "    def initialization(self, a, b, w):\n",
    "        self.a = a   # visible\n",
    "        self.b = b   # hidden\n",
    "        self.D = a.shape[0]\n",
    "        self.L = b.shape[0]\n",
    "        self.w = w\n",
    "        self.make_z_states()\n",
    "        self.H_and_G()\n",
    "        #\n",
    "    #####\n",
    "    #\n",
    "    def H_and_G(self):\n",
    "        \n",
    "        self.H_z_matrix = np.array([self.H(z) for z in self.z])  # Shape (2^L, D)\n",
    "        self.G_z_vector = np.array([self.G(z) for z in self.z])  # Shape (2^L,)\n",
    "        self.k          = np.mean(self.H_z_matrix @ self.x.T)\n",
    "        #\n",
    "    #####\n",
    "    #\n",
    "    def make_z_states(self):\n",
    "        \"\"\"\n",
    "        2^L config\n",
    "        \"\"\"\n",
    "        \n",
    "        def get_bin(i, L):\n",
    "            b = bin(i)[2:]\n",
    "            return (\"0\" * (L - len(b))) + b\n",
    "            #\n",
    "        #####\n",
    "        #\n",
    "        self.z = np.array([[int(bit) for bit in get_bin(i, self.L)]\n",
    "                                       for i in range(2 ** self.L)])\n",
    "        if self.spins:\n",
    "            self.z[self.z == 0] = -1\n",
    "            #\n",
    "        #####\n",
    "        #\n",
    "    #####\n",
    "    #\n",
    "    def H(self, z):\n",
    "        \"\"\"\n",
    "        H(z) = a + w @ z\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.a + np.dot(self.w, z)\n",
    "        #\n",
    "    #####\n",
    "    #\n",
    "    def G(self, z):\n",
    "        \"\"\"\n",
    "        G(z) = exp(b @ z).\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.exp(np.dot(self.b, z))\n",
    "        #\n",
    "    #####\n",
    "    #\n",
    "    def get_numerator(self, x):\n",
    "        \"\"\"\n",
    "        ln{sum_z[G(z) * exp[dot(H_i(z) * x_i)]]}\n",
    "        \"\"\"\n",
    "\n",
    "        # return scipy.special.logsumexp(self.H_z_matrix @ x)\n",
    "        exp_H_x   = np.exp(self.H_z_matrix @ x)  # Shape (2^L,)\n",
    "        numerator = np.sum(self.G_z_vector * exp_H_x)\n",
    "        \n",
    "        return np.log(numerator)\n",
    "        #\n",
    "    #####\n",
    "    #\n",
    "    def get_denominator(self):\n",
    "        \"\"\"\n",
    "        ln(Z) = D * ln(q) + ln{sum_z[G(z) * prod_i[(1 + H_i(z)) / q]]}\n",
    "        \"\"\"\n",
    "\n",
    "        # q average over 1+exp(H_i(z))\n",
    "        self.q = 1 + np.exp(np.mean(self.H_z_matrix))\n",
    "\n",
    "        # sum_Z\n",
    "        prod_H_q = np.prod((1 + np.exp(self.H_z_matrix)) / self.q, axis = 1)  # Shape (2^L,)\n",
    "        Z_value  = np.sum(self.G_z_vector * prod_H_q)\n",
    "\n",
    "        return self.D * np.log(self.q) + np.log(Z_value)\n",
    "        #\n",
    "    #####\n",
    "    #\n",
    "    def get_denominator_spin(self):\n",
    "        \"\"\"\n",
    "        ln(Z) = D * ln(q) + ln{sum_z[G(z) * prod_i[cosh(H_i(z)) / q]]}\n",
    "        \"\"\"\n",
    "\n",
    "        # q average over cosh(H_i(z))\n",
    "        self.q = np.cosh(np.mean(self.H_z_matrix))\n",
    "\n",
    "        # sum_Z\n",
    "        prod_H_q = np.prod(2 * np.cosh(self.H_z_matrix) / self.q, axis = 1)  # Shape (2^L,)\n",
    "        Z_value  = np.sum(self.G_z_vector * prod_H_q)\n",
    "\n",
    "        return self.D * np.log(self.q) + np.log(Z_value)    \n",
    "        #\n",
    "    #####\n",
    "    #\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        l_θ(x) = ln{sum_z[G(z) * exp(H_i(z) * x_i)]} - ln{Z}\n",
    "        \"\"\"\n",
    "        if (self.spins == False):\n",
    "            lnZ = self.get_denominator()\n",
    "        else:\n",
    "            lnZ = self.get_denominator_spin()\n",
    "            #\n",
    "        #####\n",
    "        #\n",
    "        log_likelihoods = np.array([self.get_numerator(x) - lnZ for x in self.x])\n",
    "        self.esit.append(np.mean(log_likelihoods))\n",
    "        #\n",
    "    #####\n",
    "    #\n",
    "    def save(self):\n",
    "        print(self.esit)\n",
    "        '''file = open(\"L/\" + str(self.L) + \".txt\", \"tw\")\n",
    "        file.write(str(self.esit))\n",
    "        file.close()'''\n",
    "        #\n",
    "    #####\n",
    "    #\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba297b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self, x, L, spins=False, potts=False):\n",
    "        \"\"\"\n",
    "        - x: dataset\n",
    "        - L: number of hidden units\n",
    "        - spins: if True sets x_min=-1, else x_min=0\n",
    "        \"\"\"\n",
    "        \n",
    "        if potts and spins: raise ValueError(\"Potts and Spins cannot coexist.\")\n",
    "        \n",
    "        self.x_min = -1 if spins else 0\n",
    "        self.x_max = 1\n",
    "        self.x = binarize_data(x, self.x_min, self.x_max)\n",
    "        self.data_size = len(self.x)\n",
    "        self.potts = potts\n",
    "        \n",
    "        self.D = self.x.shape[1]\n",
    "        self.L = L\n",
    "        \n",
    "        self.params = {\n",
    "            \"w\": None,\n",
    "            \"a\": None, \n",
    "            \"b\": None\n",
    "        }\n",
    "        self.params_history = {\n",
    "            \"w\": [], \n",
    "            \"a\": [], \n",
    "            \"b\": []\n",
    "        }\n",
    "        \n",
    "        self.log_likelihood = LOGlike(self.x, self.L, spins=spins)\n",
    "\n",
    "    def hinton_bias_init(self):\n",
    "        xmean = np.mean(self.x, axis=0)\n",
    "\n",
    "        # avoid divergence in log\n",
    "        delta = 1e-4\n",
    "        xmean = np.clip(xmean, self.x_min + delta, self.x_max - delta)\n",
    "\n",
    "        return np.clip(np.log(xmean-self.x_min) - np.log(self.x_max-xmean), -300, 300) \n",
    "    \n",
    "    def initialize_params(self):\n",
    "        self.params = {\n",
    "            \"w\": np.sqrt(4/(self.L + self.D)) * np.random.randn(self.D, self.L),\n",
    "            \"a\": self.hinton_bias_init(),\n",
    "            \"b\": np.zeros(self.L)\n",
    "        }\n",
    "        \n",
    "        self.params_history = {param: [self.params[param].copy()] for param in self.params.keys()}\n",
    "    \n",
    "    def contrastive_divergence(self, vector_input, weights, biases, POTTS=False):\n",
    "        H = np.clip( np.dot(vector_input, weights) + biases, -300, 300 )\n",
    "        a = np.exp( (self.x_max - self.x_min) * H )\n",
    "\n",
    "        output_size = H.shape\n",
    "        vector_output = np.full(output_size, self.x_min)\n",
    "        \n",
    "        if POTTS:\n",
    "            p = a / np.sum(a) # state probability\n",
    "            F = np.cumsum(p) # cumulative probability\n",
    "            r = np.random.rand()\n",
    "            i = 0\n",
    "            while r > F[i]:\n",
    "                i += 1\n",
    "            vector_output[i] = 1\n",
    "            \n",
    "        else:\n",
    "            p = a / (a + 1) # local probability\n",
    "            vector_output[np.random.random(output_size) < p] = self.x_max\n",
    "        \n",
    "        return vector_output\n",
    "\n",
    "    def plot_weights_bias(self, weights, biases, cols=0, s=1.5, cmap=\"bwr\", vmin=-4, vmax=4):\n",
    "        \"\"\"TODO: upgrade\"\"\"\n",
    "        rows = int(np.ceil( self.L / cols))\n",
    "        plt.clf()\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(s*(1+cols), s*rows))\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                if cols == 1:\n",
    "                    ax = axes[i]\n",
    "                else:\n",
    "                    ax = axes[i,j]\n",
    "                if i == j == 0:\n",
    "                    ax.imshow(biases.reshape((28,28)), cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "                    ax.set_title(\"bias\")\n",
    "                else:\n",
    "                    ax.imshow(weights.T[i*cols+j-1].reshape((28,28)), cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "                    ax.set_title(f\"hidden {i*cols+j}\")\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "\n",
    "        plt.subplots_adjust(hspace=.3)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def training(self, optimizer=\"RMSprop\", epochs=150, batches=20, batch_i=10, batch_f=500, \n",
    "                 lr=0.05, epsilon=1e-4, cd_steps=2, gamma=0.001, verbose=False):\n",
    "        \n",
    "        if optimizer == \"SGD\":\n",
    "            lr_i, lr_f = 1., 0.25\n",
    "        elif optimizer == \"RMSprop\":\n",
    "            lr_i = lr_f = lr\n",
    "            beta, epsilon = 0.9, epsilon\n",
    "        else:\n",
    "            raise ValueError(\"Optimizer should either be SGD or RMSprop.\")\n",
    "        \n",
    "        s = {param:np.zeros_like(self.params[param]) for param in [\"w\", \"a\", \"b\"]}\n",
    "        list_indices = np.arange(self.x.shape[0])\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "            q = (epoch - 1) / (epochs - 1)\n",
    "            batch_size = int(batch_i + (batch_f-batch_i) * q**2)\n",
    "            lr = lr_i + (lr_f-lr_i) * q\n",
    "            \n",
    "            for _ in range(batches):\n",
    "                v_data, v_model = [np.zeros(self.D) for _ in range(2)]\n",
    "                h_data, h_model = [np.zeros(self.L) for _ in range(2)]\n",
    "                vh_data, vh_model = [np.zeros((self.D,self.L)) for _ in range(2)]\n",
    "                \n",
    "                selected_indices = np.random.choice(list_indices, batch_size, replace=False)\n",
    "                for i in range(batch_size):\n",
    "                    # positive CD phase\n",
    "                    v = self.x[selected_indices[i]]\n",
    "                    h = self.contrastive_divergence(v, self.params[\"w\"], self.params[\"b\"], POTTS=self.potts)\n",
    "                    \n",
    "                    v_data += v\n",
    "                    h_data += h\n",
    "                    vh_data += np.outer(v, h)\n",
    "                    \n",
    "                    # generate fantasy data\n",
    "                    hf = h.copy()\n",
    "                    for _ in range(cd_steps):\n",
    "                        # negative CD phase\n",
    "                        vf = self.contrastive_divergence(hf, self.params[\"w\"].T, self.params[\"a\"])\n",
    "                        # positive CD phase\n",
    "                        hf = self.contrastive_divergence(vf, self.params[\"w\"], self.params[\"b\"], POTTS=self.potts)\n",
    "\n",
    "                    v_model += vf\n",
    "                    h_model += hf\n",
    "                    vh_model += np.outer(vf, hf)\n",
    "                    \n",
    "                # gradient of likelihood\n",
    "                data_models = {\n",
    "                    \"w\": (vh_data,vh_model),\n",
    "                    \"a\": (v_data,v_model),\n",
    "                    \"b\": (h_data,h_model)\n",
    "                }\n",
    "                for param,(d,m) in data_models.items():            \n",
    "                    grad_theta = (d - m) / batch_size\n",
    "                    \n",
    "                    if optimizer == \"RMSprop\":\n",
    "                        s[param] = beta * s[param] + (1-beta) * grad_theta**2\n",
    "                        new_param = lr * grad_theta / np.sqrt(epsilon + s[param])\n",
    "                    else:\n",
    "                        new_param = lr * grad_theta\n",
    "\n",
    "                    self.params[param] += new_param\n",
    "\n",
    "                    if gamma > 0:\n",
    "                        self.params[param] -= (gamma * lr) * np.sign(self.params[param])\n",
    "            \n",
    "            # save weights and biases for every epoch\n",
    "            for param in [\"w\", \"a\", \"b\"]:\n",
    "                self.params_history[param].append(self.params[param].copy())\n",
    "            \n",
    "            # plot training process\n",
    "            if verbose:\n",
    "                print(f\"Epoch: {epoch} / {epochs}\", end=\"\\r\")\n",
    "                \n",
    "                # if epoch % 20 == 0: self.plot_weights_bias(self.params[\"w\"], self.params[\"a\"], cols=self.L//2)\n",
    "        \n",
    "        print(\"Training complete.\")\n",
    "    \n",
    "    def test(self, v_test, n=200, af=1):\n",
    "        v = v_test.copy()\n",
    "        v_history = []\n",
    "        h_history = []\n",
    "        for _ in range(n):\n",
    "            h = self.contrastive_divergence(v, self.params[\"w\"], self.params[\"b\"], POTTS=self.potts)\n",
    "            v = self.contrastive_divergence(h, af*self.params[\"w\"].T, af*self.params[\"a\"])\n",
    "            v_history.append(v)\n",
    "            h_history.append(h)\n",
    "        \n",
    "        return v_history, h_history\n",
    "\n",
    "    '''def likelihood_history(self, n=5):\n",
    "        self.log_likelihood.esit = []\n",
    "        if n == 1:\n",
    "            list_ix = [-1]\n",
    "        else:\n",
    "            list_ix = np.linspace(0, len(self.params_history[\"w\"])-1, n, dtype=int)\n",
    "        self.log_likelihood.esit_ix = list_ix.copy()\n",
    "        \n",
    "        for ix in list_ix:\n",
    "            self.log_likelihood.inizialization(\n",
    "                self.params_history[\"a\"][ix], self.params_history[\"b\"][ix], self.params_history[\"w\"][ix]\n",
    "            )\n",
    "            self.log_likelihood.run()'''\n",
    "    \n",
    "    def likelihood_history(self, npoints=5, from_last=1, step_last=1):\n",
    "        if npoints == 1:\n",
    "            list_ix = [-1]\n",
    "        else:\n",
    "            n_params = len(self.params_history[\"w\"])\n",
    "\n",
    "            list_ix2 = np.arange(n_params - step_last*from_last, n_params, step_last, dtype=int).tolist()\n",
    "            list_ix1 = np.linspace(0, list_ix2[0], npoints-from_last+1, dtype=int).tolist()[:-1]\n",
    "\n",
    "            list_ix = list_ix1 + list_ix2\n",
    "        \n",
    "        self.log_likelihood.esit_ix = list_ix.copy()\n",
    "\n",
    "        for ix in list_ix:\n",
    "            self.log_likelihood.initialization(\n",
    "                self.params_history[\"a\"][ix], self.params_history[\"b\"][ix], self.params_history[\"w\"][ix]\n",
    "            )\n",
    "            self.log_likelihood.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a867b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_data(data, x_min=0, x_max=1):\n",
    "    return np.where(data/255 > 0.5, x_max, x_min)\n",
    "\n",
    "def plot_likelihood_evolutions(list_epochs, list_models_likelihoods, list_labels=None, grid=True, colors=[]):\n",
    "    colors = colors if colors else [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:pink\"]\n",
    "    \n",
    "    for i,list_likelihoods in enumerate(list_models_likelihoods):\n",
    "        label = None if list_labels is None else list_labels[i]\n",
    "        plt.plot(list_epochs, list_likelihoods, \"o-\", color=colors[i], label=label)\n",
    "    \n",
    "    if list_labels:\n",
    "        plt.legend()\n",
    "    if grid:\n",
    "        plt.grid(linestyle=\"--\", alpha=0.3)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Log-Likelihood\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_likelihood_means(x, y, yerr=None, xlabel=\"Models\"):\n",
    "    plt.bar(x, y, yerr=yerr, color=\"#00957c\", capsize=3, alpha=0.7, edgecolor=\"k\")\n",
    "    y_min, y_max = plt.ylim()\n",
    "    delta = min(y) - y_min\n",
    "    \n",
    "\n",
    "    plt.grid(alpha=0.5, linestyle=\"--\")\n",
    "    plt.ylim(y_min + 0.5*delta, max(y) + delta)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Log-likelihood\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_weights_bias(weights, biases, L, epoch=None, s=1.5, cmap=\"bwr\", vmin=-4, vmax=4):\n",
    "    rows = 2\n",
    "    cols = int(np.ceil(L/2))\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols + 1, figsize=(s*(1+cols), s*rows))\n",
    "    plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    if epoch is not None:\n",
    "        fig.suptitle(f\"Epoch {epoch}\", y=1.05)\n",
    "    \n",
    "    k=1\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if rows == 1:\n",
    "                ax = axes[j+1]\n",
    "            else:\n",
    "                ax = axes[i,j+1]\n",
    "            if k <= L:\n",
    "                ax.imshow(weights[:,k-1].reshape((28,28)), cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                ax.set_title(f\"hidden {k}\")\n",
    "            else:\n",
    "                fig.delaxes(ax)\n",
    "            k += 1\n",
    "            \n",
    "        if i > 0: \n",
    "            fig.delaxes(axes[i,0])\n",
    "\n",
    "    if rows == 1:\n",
    "        ax = axes[0]\n",
    "    else:\n",
    "        ax = axes[0,0]\n",
    "    im=ax.imshow(biases.reshape((28,28)), cmap=\"bwr\", vmin=vmin,vmax=vmax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title('bias')\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.14, 0.15, 0.024, 0.33])\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def animate_weights_bias_evolution(weights_history, biases_history, L, interval=200, s=1.5, cmap=\"bwr\", vmin=-4, vmax=4):\n",
    "    rows = 2\n",
    "    cols = int(np.ceil(L / 2))\n",
    "    epochs = len(weights_history)\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols + 1, figsize=(s*(1+cols), s*rows+.5))\n",
    "    plt.subplots_adjust(hspace=0.05, wspace=0.3, top=0.85)\n",
    "    \n",
    "    title = fig.suptitle(\"Epoch 0\", fontsize=14, y=0.97)\n",
    "\n",
    "    images = []\n",
    "    k = 1\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if rows == 1:\n",
    "                ax = axes[j+1]\n",
    "            else:\n",
    "                ax = axes[i,j+1]\n",
    "            \n",
    "            if k <= L:\n",
    "                img = ax.imshow(np.zeros((28,28)), cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "                images.append(img)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                ax.set_title(f\"hidden {k}\")\n",
    "            else:\n",
    "                fig.delaxes(ax)\n",
    "            k += 1\n",
    "\n",
    "        if i > 0:\n",
    "            fig.delaxes(axes[i,0])\n",
    "\n",
    "    if rows == 1:\n",
    "        ax = axes[0]\n",
    "    else:\n",
    "        ax = axes[0,0]\n",
    "    \n",
    "    im = ax.imshow(np.zeros((28,28)), cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(\"bias\")\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.14, 0.15, 0.024, 0.33])\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "    def update(epoch):\n",
    "        title.set_text(f\"Epoch {epoch}\")\n",
    "        biases = biases_history[epoch]\n",
    "        weights = weights_history[epoch]\n",
    "        \n",
    "        im.set_data(biases.reshape((28,28)))\n",
    "\n",
    "        for k in range(L):\n",
    "            images[k].set_data(weights[:,k].reshape((28,28)))\n",
    "\n",
    "        return [im] + images\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=epochs, interval=interval, blit=False)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c0dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all handwritten numbers from 0 to 9\n",
    "X, Y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "# numbers to keep\n",
    "list_numbers = [str(i) for i in range(10)][:3]\n",
    "index_to_keep = np.isin(Y, list_numbers)\n",
    "X_keep = X[index_to_keep]\n",
    "Y_keep = Y[index_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ac02d",
   "metadata": {},
   "source": [
    "## 2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfce186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = RBM(X_keep, 3, spins=False, potts=False)\n",
    "rbm.initialize_params()\n",
    "rbm.training(epochs=150, optimizer=\"RMSprop\")\n",
    "rbm.likelihood_history(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_e = rbm.log_likelihood.esit_ix\n",
    "list_l = rbm.log_likelihood.esit\n",
    "\n",
    "plot_likelihood_evolutions(list_e, [list_l])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07de58b9",
   "metadata": {},
   "source": [
    "## 2.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7714b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = RBM(X_keep, 3, spins=False, potts=False)\n",
    "list_l = []\n",
    "for i in range(1,4):\n",
    "    print(f\"CD_steps: {i}\")\n",
    "    rbm.initialize_params()\n",
    "    rbm.training(epochs=150, optimizer=\"RMSprop\", cd_steps=i, verbose=True)\n",
    "    rbm.likelihood_history(6)\n",
    "    list_l.append( rbm.log_likelihood.esit )\n",
    "\n",
    "list_e = rbm.log_likelihood.esit_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef21cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_likelihood_evolutions(rbm.log_likelihood.esit_ix, list_l, [f\"CD steps: {i+1}\" for i in range(len(list_l))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ddf93",
   "metadata": {},
   "source": [
    "## 2.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f782fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_L = list(range(3,11))\n",
    "list_models = []\n",
    "list_likelihoods = []\n",
    "for L in list_L:\n",
    "    print(f\"L: {L}\")\n",
    "    rbm = RBM(X_keep, L, spins=False, potts=False)\n",
    "    rbm.initialize_params()\n",
    "    rbm.training(epochs=150, optimizer=\"RMSprop\", verbose=True)\n",
    "    rbm.likelihood_history(1)\n",
    "    list_models.append(rbm)\n",
    "    list_likelihoods.append( rbm.log_likelihood.esit[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef0a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(list_L, list_likelihoods)\n",
    "# plt.grid(linestyle=\"--\")\n",
    "plt.xticks(list_L)\n",
    "plt.xlabel(\"L (number of hidden units)\")\n",
    "plt.ylabel(\"Likelihood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c3cd7d",
   "metadata": {},
   "source": [
    "# 3\n",
    "To change:\n",
    "- gradient descent\n",
    "    - type: RMSprop, SGD\n",
    "    - parameters: leraning rate, epsilon\n",
    "- spins=True/False\n",
    "- potts=True/False\n",
    "- regularization\n",
    "- ...\n",
    "\n",
    "## 3.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7bbce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_e = rbm.log_likelihood.esit_ix\n",
    "labels = [f\"run n°{i+1}\" for i in range(len(list_l))]\n",
    "cmap = cm.RdPu\n",
    "colors = [cmap(i) for i in np.linspace(0.2,0.8,len(list_l))]\n",
    "plot_likelihood_evolutions(list_e, list_l, list_labels=labels, colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8adb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_means = []\n",
    "list_std = []\n",
    "for likelihoods in list_l:\n",
    "    last_l = np.array(likelihoods[len(likelihoods)-n_last_likelihoods:])\n",
    "    list_means.append(last_l.mean())\n",
    "    list_std.append(last_l.std())\n",
    "\n",
    "plot_likelihood_means(np.arange(1,len(list_means)+1), list_means, yerr=list_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6696435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_weights_bias_evolution(rbm.params_history[\"w\"], rbm.params_history[\"a\"], rbm.L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce35cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eb5a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_l_tot = []\n",
    "for n in range(0,-5,-1):\n",
    "    rbm = RBM(X_keep, 6, spins=False, potts=False)\n",
    "    rbm.initialize_params()\n",
    "    rbm.training(epochs=50, optimizer=\"RMSprop\", lr=10**n, verbose=True)\n",
    "    rbm.likelihood_history(6)\n",
    "    \n",
    "    list_l_tot.append(rbm.log_likelihood.esit)\n",
    "    \n",
    "list_e = rbm.log_likelihood.esit_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9d5eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = list(range(0,-5,-1))\n",
    "plot_likelihood_evolutions(list_e, list_l_tot, list_labels=[f\"learning rate = 10^{n}\" for n in ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a242bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_l_tot = []\n",
    "for n in range(-9,-3):\n",
    "    rbm = RBM(X_keep, 6, spins=False, potts=False)\n",
    "    rbm.initialize_params()\n",
    "    rbm.training(epochs=50, optimizer=\"RMSprop\", epsilon=10**n, verbose=True)\n",
    "    rbm.likelihood_history(6)\n",
    "    \n",
    "    list_l_tot.append(rbm.log_likelihood.esit)\n",
    "    \n",
    "list_e = rbm.log_likelihood.esit_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = list(range(-9,-3))\n",
    "plot_likelihood_evolutions(list_e, list_l_tot, list_labels=[rf\"$\\epsilon$ = 10^{n}\" for n in ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a60e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 10\n",
    "epochs = 150\n",
    "n_likelihoods = 6\n",
    "\n",
    "rbm_sgd = RBM(X_keep, L)\n",
    "rbm_sgd.initialize_params()\n",
    "rbm_sgd.training(epochs=epochs, optimizer=\"SGD\")\n",
    "rbm_sgd.likelihood_history(n_likelihoods)\n",
    "\n",
    "rbm_rms = RBM(X_keep, L)\n",
    "rbm_rms.initialize_params()\n",
    "rbm_rms.training(epochs=epochs, optimizer=\"RMSprop\", epsilon=1e-8)\n",
    "rbm_rms.likelihood_history(n_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d877135",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_e = rbm_sgd.log_likelihood.esit_ix\n",
    "list_l_sgd = rbm_sgd.log_likelihood.esit\n",
    "list_l_rms = rbm_rms.log_likelihood.esit\n",
    "\n",
    "plot_likelihood_evolutions(list_e, [list_l_sgd, list_l_rms], list_labels=[\"SGD\", \"RMS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_l_tot = []\n",
    "gamma_values = [f\"10**{n}\" if n != 0 else \"0\" for n in range(-5,1)]\n",
    "for gamma in gamma_values:\n",
    "    rbm = RBM(X_keep, 6)\n",
    "    rbm.initialize_params()\n",
    "    rbm.training(epochs=50, optimizer=\"RMSprop\", gamma=eval(gamma), verbose=True)\n",
    "    rbm.likelihood_history(6)\n",
    "    \n",
    "    list_l_tot.append(rbm.log_likelihood.esit)\n",
    "    \n",
    "list_e = rbm.log_likelihood.esit_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_likelihood_evolutions(list_e, list_l_tot, list_labels=[rf\"$\\gamma$ = {gamma_values[i].replace('**', '^')}\" for i in range(len(list_l_tot))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0f40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e217e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 10\n",
    "epochs = 150\n",
    "n_likelihoods = 6\n",
    "lr = 1e-1\n",
    "epsilon = 1e-8\n",
    "gamma = 1e-4\n",
    "\n",
    "# RMSprop\n",
    "print(\"Bernoulli\")\n",
    "rbm_bern = RBM(X_keep, L)\n",
    "rbm_bern.initialize_params()\n",
    "rbm_bern.training(epochs=epochs, optimizer=\"RMSprop\", epsilon=epsilon, gamma=gamma, verbose=True)\n",
    "rbm_bern.likelihood_history(n_likelihoods)\n",
    "\n",
    "'''print(\"Spins\")\n",
    "rbm_spin = RBM(X_keep, L, spins=True)\n",
    "rbm_spin.initialize_params()\n",
    "rbm_spin.training(epochs=epochs, optimizer=\"RMSprop\", epsilon=epsilon, gamma=gamma, verbose=True)\n",
    "rbm_spin.likelihood_history(n_likelihoods)'''\n",
    "\n",
    "print(\"POTTS\")\n",
    "rbm_potts = RBM(X_keep, L, potts=True)\n",
    "rbm_potts.initialize_params()\n",
    "rbm_potts.training(epochs=epochs, optimizer=\"RMSprop\", epsilon=epsilon, gamma=gamma, verbose=True)\n",
    "rbm_potts.likelihood_history(n_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_likelihood_evolutions(list_e, [list_l_bern, list_l_spin, list_l_potts], list_labels=[\"Bernoulli\", \"Spins\", \"POTTS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5da94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 10\n",
    "epochs = 150\n",
    "n_likelihoods = 6\n",
    "gamma = 1e-4\n",
    "\n",
    "# SGD\n",
    "print(\"Bernoulli\")\n",
    "rbm_bern = RBM(X_keep, L)\n",
    "rbm_bern.initialize_params()\n",
    "rbm_bern.training(epochs=epochs, optimizer=\"SGD\", gamma=gamma, verbose=True)\n",
    "rbm_bern.likelihood_history(n_likelihoods)\n",
    "\n",
    "'''print(\"Spins\")\n",
    "rbm_spin = RBM(X_keep, L, spins=True)\n",
    "rbm_spin.initialize_params()\n",
    "rbm_spin.training(epochs=epochs, optimizer=\"SGD\", gamma=gamma, verbose=True)\n",
    "rbm_spin.likelihood_history(n_likelihoods)'''\n",
    "\n",
    "print(\"POTTS\")\n",
    "rbm_potts = RBM(X_keep, L, potts=True)\n",
    "rbm_potts.initialize_params()\n",
    "rbm_potts.training(epochs=epochs, optimizer=\"SGD\", gamma=gamma, verbose=True)\n",
    "rbm_potts.likelihood_history(n_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_likelihood_evolutions(list_e, [list_l_bern, list_l_spin, list_l_potts], list_labels=[\"Bernoulli\", \"Spins\", \"POTTS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c64ed66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad58f4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35e9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c0af7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c9300e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca9403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7518e6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d6456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc0d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = RBM(X_keep, 5, spins=True)\n",
    "rbm.initialize_params()\n",
    "rbm.training(epochs=20, optimizer=\"SGD\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d30231",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm.log_likelihood.esit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb688ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd88c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3649d596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857bb491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660428b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf5410f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99b0cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba1380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "605a0238",
   "metadata": {},
   "source": [
    "Let's check if something changes when a simulation is run with the same hyperparameters different times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c4264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebea38e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_l = []\n",
    "N = 5\n",
    "n_last_likelihoods = 6\n",
    "steps=6\n",
    "for n in range(N):\n",
    "    print(f\"n run: {n}\")\n",
    "    rbm = RBM(X_keep, 10)\n",
    "    rbm.initialize_params()\n",
    "    rbm.training(epochs=150, optimizer=\"RMSprop\", epsilon=1e-8, gamma=1e-4, verbose=True)\n",
    "    rbm.likelihood_history(12,n_last_likelihoods, steps)\n",
    "    list_l.append(rbm.log_likelihood.esit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b80d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ba7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf218c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4d7827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa85559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3db00b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84d31ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bfb3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f80df04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e18e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194fb96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d67c10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542056b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = \"Reds\"\n",
    "ix = np.random.choice(len(X_keep))\n",
    "x_test = binarize_data(X_keep[ix])\n",
    "v, _ = rbm.test(x_test)\n",
    "\n",
    "fig,axes = plt.subplots(1,2,figsize=(10,5))\n",
    "axes[0].imshow(binarize_data(X_keep[ix], 0, 1).reshape((28,28)), cmap=cmap)\n",
    "axes[1].imshow(v[-1].reshape((28,28)), cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d7700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bf5f554",
   "metadata": {},
   "source": [
    "## Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a60d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = RBM(X_keep, 3, spins=True, potts=False)\n",
    "rbm.initialize_params()\n",
    "rbm.training(epochs=20, optimizer=\"SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aacd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm.likelihood_history(5)\n",
    "print(rbm.log_likelihood.esit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47237d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = \"Reds\"\n",
    "ix = np.random.choice(len(X_keep))\n",
    "x_test = binarize_data(X_keep[ix], -1)\n",
    "v, _ = rbm.test(x_test)\n",
    "\n",
    "fig,axes = plt.subplots(1,2,figsize=(10,5))\n",
    "axes[0].imshow(X_keep[ix].reshape((28,28)), cmap=cmap)\n",
    "axes[1].imshow(v[-1].reshape((28,28)), cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba4748",
   "metadata": {},
   "source": [
    "## POTTS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c9ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = RBM(X_keep, 12, spins=False, potts=True)\n",
    "rbm.initialize_params()\n",
    "rbm.training(epochs=120, optimizer=\"RMSprop\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c47ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = \"Reds\"\n",
    "ix = np.random.choice(len(X_keep))\n",
    "x_test = binarize_data(X_keep[ix])\n",
    "v, _ = rbm.test(x_test)\n",
    "\n",
    "fig,axes = plt.subplots(1,2,figsize=(10,5))\n",
    "axes[0].imshow(X_keep[ix].reshape((28,28)), cmap=cmap)\n",
    "axes[1].imshow(v[-1].reshape((28,28)), cmap=cmap)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
